# OriginDL 设计文档

## 设计理念

OriginDL 的设计遵循以下核心理念：

1. **简洁性** - 提供直观易用的 API，降低学习成本
2. **可扩展性** - 支持多种计算后端，便于未来扩展
3. **性能** - 支持多种高性能计算后端
4. **教育性** - 从零开始构建，便于理解深度学习框架原理

## 系统架构

### 核心组件

#### 1. Tensor 类设计

```cpp
/*
Tensor 架构层次：
Tensor (用户接口)
    ↓ 只调用TensorImpl方法
TensorImpl (核心实现)
    ↓ 只调用Mat接口方法
Mat (抽象接口)
    ↓ 具体实现
Torch/Origin Mat (具体后端)
*/
```

**设计特点：**
- **值语义** - Tensor 对象可以像普通值一样传递和复制
- **浅拷贝** - 多个 Tensor 对象可以共享同一个 TensorImpl
- **智能指针管理** - 使用 shared_ptr 自动管理内存
- **抽象层隔离** - 通过 Mat 接口隔离具体后端实现

#### 2. 自动求导系统

**计算图构建：**
- 每个 Tensor 记录其创建者（Operator）
- 前向传播时自动构建计算图
- 反向传播时按拓扑序计算梯度

**梯度计算：**
- 每个 Operator 实现 forward 和 backward 方法
- 支持多输入多输出的复杂算子
- 自动处理梯度累积和清零

#### 3. 算子系统

**算子基类：**
```cpp
class Operator : public std::enable_shared_from_this<Operator> {
public:
    virtual std::vector<Tensor> forward(const std::vector<Tensor> &inputs) = 0;
    virtual std::vector<Tensor> backward(const std::vector<Tensor> &grad_outputs) = 0;
};
```

**设计原则：**
- **纯虚函数** - 强制子类实现 forward 和 backward
- **多输入支持** - 支持任意数量的输入张量
- **计算图管理** - 自动设置 creator 和计算图信息

## 技术决策

### 1. 后端选择：多后端支持

**支持的后端：**
- **LibTorch** - 基于PyTorch的C++后端，支持CPU和GPU
- **OriginMat** - 自研的CPU后端，用于教育和学习
- **可扩展性** - 易于添加新的计算后端

**替代方案考虑：**
- **Eigen** - 功能强大但主要面向线性代数
- **自定义实现** - 开发成本高，维护困难
- **其他库** - 如 Intel MKL，但绑定特定硬件

### 2. 内存管理策略

**智能指针使用：**
```cpp
// Tensor 使用 shared_ptr 管理 TensorImpl
TensorImplPtr impl_;

// Operator 使用 shared_ptr 管理输出张量
std::vector<std::shared_ptr<Tensor>> outputs_;
```

**设计权衡：**
- **优点** - 自动内存管理，避免内存泄漏
- **缺点** - 可能存在循环引用风险
- **解决方案** - 仔细设计所有权关系，必要时使用 weak_ptr

### 3. 异常处理策略

**设计原则：**
- **异常优于错误码** - 提供更清晰的错误信息
- **类型安全** - 使用强类型异常类
- **性能考虑** - 异常只在真正错误时抛出

**异常层次：**
```cpp
class DLException : public std::exception { };
class ShapeMismatchException : public DLException { };
class InvalidOperationException : public DLException { };
```

### 4. 张量打印系统设计

#### 4.1 设计目标

OriginDL的张量打印系统旨在提供清晰、直观的张量数据展示，同时保持与主流深度学习框架的一致性。


#### 打印格式设计

**格式层次：**

1. **标量张量 (0维)**
   ```
   (1.0)
   ```

2. **一维张量 (1维)**
   ```
   [1.0, 2.0, 3.0]
   ```

3. **二维张量 (2维)**
   ```
   [[1, 2, 3],
    [4, 5, 6]]
   ```

4. **高维张量 (3维及以上，如4维打印如下)**
   ```
   (0,0,.,.) = 
        0       1       2
        3       4       5
   (0,1,.,.) = 
        6       7       8
        9      10      11
   ```

不同的深度学习框架打印 shape(2,3,2,3) 的效果，裸数据均为数组[0, 1, 2, ..., 33, 34, 35]。

```
# pytorch 打印如下
tensor([[[[ 0.,  1.,  2.],
          [ 3.,  4.,  5.]],

         [[ 6.,  7.,  8.],
          [ 9., 10., 11.]],

         [[12., 13., 14.],
          [15., 16., 17.]]],


        [[[18., 19., 20.],
          [21., 22., 23.]],

         [[24., 25., 26.],
          [27., 28., 29.]],

         [[30., 31., 32.],
          [33., 34., 35.]]]])

# libtorch 打印如下：
(1,1,.,.) = 
  0  1  2
  3  4  5

(2,1,.,.) = 
  18  19  20
  21  22  23

(1,2,.,.) = 
   6   7   8
   9  10  11

(2,2,.,.) = 
  24  25  26
  27  28  29

(1,3,.,.) = 
  12  13  14
  15  16  17

(2,3,.,.) = 
  30  31  32
  33  34  35
[ CPUFloatType{2,3,2,3} ]
```

本人认为 libtorch 的切片风格，再高维张张量中可以更好的看到细节，因此采用了切片的方式，其次 libtorch 的打印内容存在跳跃，与内存布局0~35的连续顺序不合，此时 Pytorch 的打印风格与内存布局相符。 Origin 结合了这两者的风格，打印效果如下所示：
```
(0,0,.,.) = 
     0       1       2
     3       4       5
(0,1,.,.) = 
     6       7       8
     9      10      11
(0,2,.,.) = 
    12      13      14
    15      16      17
(1,0,.,.) = 
    18      19      20
    21      22      23
(1,1,.,.) = 
    24      25      26
    27      28      29
(1,2,.,.) = 
    30      31      32
    33      34      35

 OriginMat(shape=[2, 3, 2, 3], dtype=float32, device=cpu)
```

切片打印的顺序:
```
// LibTorch风格
(0,0,.,.) → (1,0,.,.) → (0,1,.,.) → (1,1,.,.) → (0,2,.,.) → (1,2,.,.)

// OriginDL 风格
(0,0,.,.) → (0,1,.,.) → (0,2,.,.) → (1,0,.,.) → (1,1,.,.) → (1,2,.,.)


内存布局: [0,1,2,3,4,5, 6,7,8,9,10,11, 12,13,14,15,16,17, 18,19,20,21,22,23, ...]
          ↑─────────↑  ↑─────────↑  ↑─────────↑  ↑─────────↑
          (0,0,.,.)   (0,1,.,.)   (0,2,.,.)   (1,0,.,.)


LibTorch风格的访问顺序：
- `(0,0,.,.)` → 内存地址 0-5
- `(1,0,.,.)` → 内存地址 18-23 (跳跃13个元素)
- `(0,1,.,.)` → 内存地址 6-11 (回跳17个元素)
从内存布局上看，OriginDL中打印的相邻切片在内存布局上是相邻的。
```

使用0-based索引，从编程习惯上，更符合符合C++/Python等主流编程语言的索引约定。

```cpp
// OriginDL采用0-based索引，第一个切片索引为 (0,0,.,.)
(0,0,.,.) = 
     0       1       2
     3       4       5

// 而不是LibTorch的1-based索引，第一个切片的索引为 (1,1,.,.)
(1,1,.,.) = 
     0       1       2
     3       4       5
```




