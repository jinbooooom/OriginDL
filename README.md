 <p align="center" style="line-height:0; font-size:0">
   <img src="./assets/README/logo_compact.svg" height="200" alt="logo" style="vertical-align:middle" /><img src="./assets/README/origindl_text_italic.svg" height="80" alt="OriginDL" style="vertical-align:middle" />
 </p>


# OriginDL: å®Œå…¨ä»é›¶å¼€å§‹æ„å»ºçš„æ·±åº¦å­¦ä¹ æ¡†æ¶

OriginDL æ˜¯ä¸€ä¸ª**å®Œå…¨ä»é›¶å¼€å§‹æ„å»º**çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé‡‡ç”¨ C++ å®ç°ã€‚OriginDL ä¸ä»…å®ç°äº†é«˜å±‚çš„è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿï¼Œæ›´ä»æœ€åº•å±‚çš„çŸ©é˜µè¿ç®—å¼€å§‹ï¼Œä½¿ç”¨ CUDA æ‰‹å†™äº† GPU åŠ é€Ÿçš„çŸ©é˜µè®¡ç®—æ ¸å¿ƒï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæ„å»ºäº†å®Œæ•´çš„è‡ªåŠ¨æ±‚å¯¼å¼•æ“å’Œç¥ç»ç½‘ç»œæ¨¡å—ã€‚ç›®å‰å·²åœ¨æ¡†æ¶ä¸Šå®ç°äº†çº¿æ€§å›å½’ä¸ MNIST æ‰‹å†™æ•°å­—è¯†åˆ«çš„è®­ç»ƒç¤ºä¾‹ï¼Œä»¥åŠåŸºäº PNNX çš„ YOLOv5 ç›®æ ‡æ£€æµ‹æ¨ç†ï¼Œç”¨äºéªŒè¯è‡ªåŠ¨æ±‚å¯¼ä¸æ¨ç†é“¾è·¯ã€‚

OriginDL æä¾›äº†ç±»ä¼¼ PyTorch çš„ API æ¥å£ï¼Œå¹¶é…æœ‰[è¯¦ç»†çš„è®¾è®¡æ–‡æ¡£å’Œç”¨æˆ·æŒ‡å—](#-æ–‡æ¡£)ï¼Œå¸®åŠ©å¯¹æ¡†æ¶åº•å±‚å®ç°æ„Ÿå…´è¶£çš„æœ‹å‹æ·±å…¥ç†è§£æ·±åº¦å­¦ä¹ æ¡†æ¶çš„åº•å±‚å®ç°åŸç†ã€‚

OriginDL æ˜¯æœ¬äººåœ¨ä¸šä½™æ—¶é—´å®ç°çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚æœ¬äººå¹¶éæ·±åº¦å­¦ä¹ æ¡†æ¶é¢†åŸŸçš„ä¸“ä¸šäººå£«ï¼Œä½†å¯¹æ·±åº¦å­¦ä¹ è®­ç»ƒå’Œæ¨ç†çš„åº•å±‚åŸç†æŠ±æœ‰æµ“åšå…´è¶£ï¼Œå¸Œæœ›é€šè¿‡äº²æ‰‹å®ç°ä¸€ä¸ªå®Œæ•´çš„æ¡†æ¶æ¥æ·±å…¥ç†è§£å…¶è®¾è®¡ä¸å®ç°ç»†èŠ‚ã€‚é€šè¿‡æ‰‹å†™åº•å±‚çŸ©é˜µè®¡ç®—æ ¸å¿ƒï¼Œæœ¬äººä¹Ÿå¸Œæœ›å€Ÿæ­¤æœºä¼šæ·±å…¥å­¦ä¹  CUDA é«˜æ€§èƒ½ç¼–ç¨‹ï¼Œæ‹“å®½æŠ€æœ¯è§†é‡ã€‚

ç”±äºä¸ªäººèƒ½åŠ›å’Œæ—¶é—´æœ‰é™ï¼ŒOriginDL ä¸­éš¾å…å­˜åœ¨ä¸€äº›ä¸è¶³ä¹‹å¤„å’Œå¾…å®Œå–„çš„åŠŸèƒ½ã€‚éå¸¸æ¬¢è¿å¤§å®¶ä¸€èµ·å­¦ä¹ äº¤æµï¼Œå¦‚æœæ‚¨åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­å‘ç°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œæ¬¢è¿æäº¤ Issue æˆ– Pull Requestï¼

## ğŸ¯ é¡¹ç›®æˆæœå±•ç¤º

### çº¿æ€§å›å½’è®­ç»ƒ

ä½¿ç”¨è‡ªåŠ¨æ±‚å¯¼åŠŸèƒ½å®ç°ç®€å•çš„çº¿æ€§å›å½’ y = wx + bï¼Œå¿«é€Ÿæ”¶æ•›åˆ°ç›®æ ‡å‚æ•°ï¼ˆwâ‰ˆ2.0, bâ‰ˆ5.0ï¼‰ï¼š

```shell
$ ./build/bin/example/example_nn_linear 
CUDA devices available: 1
Device 0: NVIDIA GeForce RTX 4060 Ti
  Compute capability: 8.9
  Memory: 8187 MB
  Multiprocessors: 34
  Max threads per block: 1024
Use Device: cuda:0
iter0: loss = 28.650475, w = 0.14491756, b = 0.9844595
iter10: loss = 0.41739, w = 1.698714, b = 4.542575
iter20: loss = 0.014293473, w = 1.9443718, b = 4.9402785
iter30: loss = 0.008061945, w = 1.9816686, b = 4.985405
iter40: loss = 0.007958472, w = 1.9871883, b = 4.990613
......
iter180: loss = 0.007956621, w = 1.9881259, b = 4.9913087
iter190: loss = 0.007956621, w = 1.9881259, b = 4.9913087
iter199: loss = 0.007956621, w = 1.9881259, b = 4.9913087
```

### YOLOv5 ç›®æ ‡æ£€æµ‹

```shell
# ä½¿ç”¨çš„è®¾å¤‡ä¸º Device 0: NVIDIA GeForce RTX 4060 Ti
$ ./build/bin/example/example_yolov5 -i data/imgs/ -o data/outputs/ -p model/pnnx/yolo/yolov5n_small.pnnx.param -b model/pnnx/yolo/yolov5n_small.pnnx.bin 
air.jpg: airplane 0.92
bus.jpg: person 0.85
bus.jpg: bus 0.84
bus.jpg: person 0.69
bus.jpg: person 0.49
car.jpg: car 0.63
dog.jpg: car 0.75
dog.jpg: dog 0.64
Processed 4 images in total, Input resolution: 320x320, Batch size: 4
Total inference time: 0.1189 seconds, Average FPS: 33.65
```

<table>
<tr>
<td width="50%"><img src="./assets/README/output_air.jpg" alt="Airplane Detection" style="width:100%"></td>
<td width="50%"><img src="./assets/README/output_car.jpg" alt="Car Detection" style="width:100%"></td>
</tr>
<tr>
<td width="50%"><img src="./assets/README/output_bus.jpg" alt="Bus Detection" style="width:100%"></td>
<td width="50%"><img src="./assets/README/output_dog.jpg" alt="Dog Detection" style="width:100%"></td>
</tr>
</table>
### MNIST æ‰‹å†™æ•°å­—è¯†åˆ«

```shell
$ export ORIGIN_LOG_LEVEL=trace
$ ./build/bin/example/example_mlp_mnist -e 5 -b 512 -l 0.001 -p ./data/mnist -d 0
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:main:206] Device: cuda:0
CUDA devices available: 1
Device 0: NVIDIA GeForce RTX 4060 Ti
  Compute capability: 8.9
  Memory: 8187 MB
  Multiprocessors: 34
  Max threads per block: 1024
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:main:214] === MNIST Handwritten Digit Recognition Demo (MLP) ===
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:36] === Training Configuration ===
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:37] Max epochs: 10
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:38] Batch size: 512
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:39] Hidden size: 1000
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:40] Learning rate: 0.001
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:41] Weight decay: 0.0001
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:42] Log interval: 50
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:43] Model path: model/mnist_mlp_model.odl
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:44] Checkpoint dir: model/checkpoints
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:45] Checkpoint interval: 5 epochs
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:46] Random seed: 42
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:47] Data dir: ./data/mnist
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:48] Device id: 0 (-2=auto -1=CPU >=0=GPU)
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:print:49] ==============================
JinboBook 2026-02-12 00:18:16.991 I 198450 198450 [mlp_mnist.cpp:main:217] Loading MNIST dataset...
JinboBook 2026-02-12 00:18:18.259 I 198450 198450 [mlp_mnist.cpp:main:221] Train dataset size: 60000
JinboBook 2026-02-12 00:18:18.259 I 198450 198450 [mlp_mnist.cpp:main:222] Test dataset size: 10000
JinboBook 2026-02-12 00:18:18.259 I 198450 198450 [mlp_mnist.cpp:main:227] Creating MLP model...
JinboBook 2026-02-12 00:18:18.310 I 198450 198450 [mlp_mnist.cpp:main:230] Model created with 6 parameters
JinboBook 2026-02-12 00:18:18.311 D 198450 198450 [optimizer.cpp:collect_parameters:16]    Optimizer::collect_parameters: collected 6 parameters
JinboBook 2026-02-12 00:18:18.311 I 198450 198450 [mlp_mnist.cpp:main:236] Starting training...
JinboBook 2026-02-12 00:18:18.311 I 198450 198450 [mlp_mnist.cpp:main:239] ========== Epoch 1/10 ==========
JinboBook 2026-02-12 00:18:18.787 I 198450 198450 [mlp_mnist.cpp:main:311] Epoch 1/10 Batch 50 Loss: 0.4744 Acc: 86.87%
JinboBook 2026-02-12 00:18:19.162 I 198450 198450 [mlp_mnist.cpp:main:311] Epoch 1/10 Batch 100 Loss: 0.3254 Acc: 90.85%
JinboBook 2026-02-12 00:18:19.302 I 198450 198450 [mlp_mnist.cpp:main:320] Epoch 1/10 Training Complete - Loss: 0.2974 Acc: 91.58%
JinboBook 2026-02-12 00:18:19.302 I 198450 198450 [mlp_mnist.cpp:main:324] Evaluating on test set...
JinboBook 2026-02-12 00:18:19.357 I 198450 198450 [mlp_mnist.cpp:main:386] ========== Epoch 1/10 Summary ==========
JinboBook 2026-02-12 00:18:19.357 I 198450 198450 [mlp_mnist.cpp:main:387]   Train Loss: 0.2974, Train Acc: 91.58%
JinboBook 2026-02-12 00:18:19.357 I 198450 198450 [mlp_mnist.cpp:main:388]   Test Loss:  0.1224, Test Acc:  96.49%
JinboBook 2026-02-12 00:18:19.357 I 198450 198450 [mlp_mnist.cpp:main:389] ===========================================
JinboBook 2026-02-12 00:18:19.357 I 198450 198450 [mlp_mnist.cpp:main:239] ========== Epoch 2/10 ==========
JinboBook 2026-02-12 00:18:19.719 I 198450 198450 [mlp_mnist.cpp:main:311] Epoch 2/10 Batch 50 Loss: 0.0999 Acc: 97.01%
JinboBook 2026-02-12 00:18:20.082 I 198450 198450 [mlp_mnist.cpp:main:311] Epoch 2/10 Batch 100 Loss: 0.0981 Acc: 97.05%
JinboBook 2026-02-12 00:18:20.224 I 198450 198450 [mlp_mnist.cpp:main:320] Epoch 2/10 Training Complete - Loss: 0.0974 Acc: 97.05%
JinboBook 2026-02-12 00:18:20.224 I 198450 198450 [mlp_mnist.cpp:main:324] Evaluating on test set...
JinboBook 2026-02-12 00:18:20.276 I 198450 198450 [mlp_mnist.cpp:main:386] ========== Epoch 2/10 Summary ==========
JinboBook 2026-02-12 00:18:20.277 I 198450 198450 [mlp_mnist.cpp:main:387]   Train Loss: 0.0974, Train Acc: 97.05%
JinboBook 2026-02-12 00:18:20.277 I 198450 198450 [mlp_mnist.cpp:main:388]   Test Loss:  0.0849, Test Acc:  97.29%
JinboBook 2026-02-12 00:18:20.277 I 198450 198450 [mlp_mnist.cpp:main:389] ===========================================
# çœç•¥ä¸­é—´è®­ç»ƒçš„è¿‡ç¨‹
JinboBook 2026-02-12 00:18:26.842 I 198450 198450 [mlp_mnist.cpp:main:239] ========== Epoch 10/10 ==========
JinboBook 2026-02-12 00:18:27.211 I 198450 198450 [mlp_mnist.cpp:main:311] Epoch 10/10 Batch 50 Loss: 0.0129 Acc: 99.64%
JinboBook 2026-02-12 00:18:27.578 I 198450 198450 [mlp_mnist.cpp:main:311] Epoch 10/10 Batch 100 Loss: 0.0122 Acc: 99.68%
JinboBook 2026-02-12 00:18:27.724 I 198450 198450 [mlp_mnist.cpp:main:320] Epoch 10/10 Training Complete - Loss: 0.0129 Acc: 99.65%
JinboBook 2026-02-12 00:18:27.724 I 198450 198450 [mlp_mnist.cpp:main:324] Evaluating on test set...
JinboBook 2026-02-12 00:18:27.781 I 198450 198450 [mlp_mnist.cpp:main:386] ========== Epoch 10/10 Summary ==========
JinboBook 2026-02-12 00:18:27.781 I 198450 198450 [mlp_mnist.cpp:main:387]   Train Loss: 0.0129, Train Acc: 99.65%
JinboBook 2026-02-12 00:18:27.781 I 198450 198450 [mlp_mnist.cpp:main:388]   Test Loss:  0.0595, Test Acc:  98.29%
JinboBook 2026-02-12 00:18:27.781 I 198450 198450 [mlp_mnist.cpp:main:389] ===========================================
JinboBook 2026-02-12 00:18:27.828 I 198450 198450 [mlp_mnist.cpp:main:412] Checkpoint saved to model/checkpoints/checkpoint_epoch_10.ckpt
JinboBook 2026-02-12 00:18:27.828 I 198450 198450 [mlp_mnist.cpp:main:421] Training completed!
JinboBook 2026-02-12 00:18:27.828 I 198450 198450 [mlp_mnist.cpp:main:423] Saving model to model/mnist_mlp_model.odl...
JinboBook 2026-02-12 00:18:27.863 I 198450 198450 [mlp_mnist.cpp:main:429] Model saved successfully to model/mnist_mlp_model.odl
```

# OriginDL é¡¹ç›®ä»‹ç»

## âœ¨ ç‰¹æ€§

- ğŸš€ **è‡ªåŠ¨æ±‚å¯¼** - æ”¯æŒåŠ¨æ€è®¡ç®—å›¾å’Œåå‘ä¼ æ’­ï¼Œè‡ªåŠ¨æ„å»ºè®¡ç®—å›¾
- ğŸ“¦ **ç®€æ´ API** - ç±»ä¼¼ PyTorch çš„ç›´è§‚æ¥å£ï¼Œé™ä½å­¦ä¹ æˆæœ¬
- ğŸ¯ **æ•™è‚²å‹å¥½** - ä»é›¶æ„å»ºï¼Œä»£ç æ¸…æ™°ï¼Œä¾¿äºç†è§£æ·±åº¦å­¦ä¹ æ¡†æ¶åŸç†
- ğŸ§ª **å®Œæ•´æµ‹è¯•** - åŒ…å«å•å…ƒæµ‹è¯•å’Œä¸ PyTorch çš„å¯¹æ¯”éªŒè¯
- ğŸ§  **ç¥ç»ç½‘ç»œæ¨¡å—** - æ”¯æŒ Moduleã€Layerã€Sequential ç­‰æ¨¡å—åŒ–è®¾è®¡
- âš¡ **é«˜æ€§èƒ½æ¨ç†** - é›†æˆ PNNX é™æ€å›¾æ¨ç†ï¼ŒYOLOv5 æ¨ç†æ€§èƒ½ä¼˜åŒ–è‡³ 59 æ¯«ç§’
- ğŸ”§ **å¤šåç«¯æ”¯æŒ** - æ”¯æŒ LibTorch å’Œ OriginMatï¼ˆCPU/CUDAï¼‰åç«¯ï¼Œå¯çµæ´»åˆ‡æ¢
  - OriginMat CUDAï¼šé‡ç‚¹ä¼˜åŒ–çš„è‡ªç ” GPU åç«¯ï¼Œæ”¯æŒ CUDA åŠ é€Ÿï¼Œç”¨äºé”»ç‚¼ CUDA ç¼–ç¨‹èƒ½åŠ›
  - OriginMat CPUï¼šåŸç”Ÿå®ç°ï¼Œç”¨äºå¿«é€ŸéªŒè¯å’Œå¼€å‘
  - LibTorchï¼šä½œä¸ºå¤šåç«¯æ¶æ„çš„éªŒè¯ï¼Œç›®å‰ä»…æ”¯æŒåŸºç¡€ç®—å­

## ğŸ“ é¡¹ç›®ç»“æ„

```
OriginDL/
â”œâ”€â”€ include/origin/          # å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒæ¨¡å—ï¼ˆTensorã€Operatorã€Parameterï¼‰
â”‚   â”œâ”€â”€ nn/                 # ç¥ç»ç½‘ç»œæ¨¡å—
â”‚   â”œâ”€â”€ optim/              # ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ data/               # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ io/                 # æ¨¡å‹ IO
â”‚   â”œâ”€â”€ mat/                # çŸ©é˜µè®¡ç®—æŠ½è±¡å±‚
â”‚   â”œâ”€â”€ operators/          # ç®—å­å®ç°
â”‚   â””â”€â”€ pnnx/               # PNNX é™æ€å›¾æ¨ç†
â”œâ”€â”€ src/                    # æºæ–‡ä»¶
â”œâ”€â”€ tests/                  # æµ‹è¯•å’Œç¤ºä¾‹
â”‚   â”œâ”€â”€ unit_test/         # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ benchmark/         # æ€§èƒ½æµ‹è¯•
â”‚   â””â”€â”€ example/            # åº”ç”¨ç¤ºä¾‹
â”‚       â”œâ”€â”€ linear_regression/  # çº¿æ€§å›å½’è®­ç»ƒ
â”‚       â”œâ”€â”€ mnist/             # MNIST æ•°æ®é›†è®­ç»ƒï¼ˆMLP å’Œ CNNï¼‰
â”‚       â”œâ”€â”€ resnet/            # ResNet åˆ†ç±»æ¨ç†
â”‚       â””â”€â”€ yolo/              # YOLOv5 ç›®æ ‡æ£€æµ‹æ¨ç†
â”œâ”€â”€ docs/                   # æ–‡æ¡£
â”‚   â”œâ”€â”€ design/            # è®¾è®¡æ–‡æ¡£
â”‚   â””â”€â”€ user_guide/        # ç”¨æˆ·æŒ‡å—
â””â”€â”€ CMakeLists.txt         # æ„å»ºé…ç½®
```

## ğŸ“š æ–‡æ¡£

è¯¦ç»†çš„æ–‡æ¡£è¯·å‚è€ƒ [docs/](docs/) ç›®å½•ï¼š

- **[è®¾è®¡æ–‡æ¡£](docs/design/)** - ç³»ç»Ÿæ¶æ„è®¾è®¡ã€å®ç°åŸç†
  - [æ¶æ„è®¾è®¡æ–‡æ¡£](docs/design/architecture.md) - å®Œæ•´çš„ç³»ç»Ÿæ¶æ„è®¾è®¡
    - [1. æ¶æ„æ€»è§ˆä¸è®¾è®¡ç†å¿µ](docs/design/architecture.md#1-æ¶æ„æ€»è§ˆä¸è®¾è®¡ç†å¿µ)
    - [2. Tensor ç³»ç»Ÿæ¶æ„](docs/design/architecture.md#2-tensor-ç³»ç»Ÿæ¶æ„)
    - [3. åŠ¨æ€è®¡ç®—å›¾æ„å»º](docs/design/architecture.md#3-åŠ¨æ€è®¡ç®—å›¾æ„å»º)
    - [4. åå‘ä¼ æ’­å®ç°](docs/design/architecture.md#4-åå‘ä¼ æ’­å®ç°)
    - [5. ç®—å­ç³»ç»Ÿæ¶æ„](docs/design/architecture.md#5-ç®—å­ç³»ç»Ÿæ¶æ„)
    - [6. ç¥ç»ç½‘ç»œæ¨¡å—æ¶æ„](docs/design/architecture.md#6-ç¥ç»ç½‘ç»œæ¨¡å—æ¶æ„)
    - [7. ä¼˜åŒ–å™¨æ¶æ„](docs/design/architecture.md#7-ä¼˜åŒ–å™¨æ¶æ„)
    - [8. æ•°æ®å¤„ç†æ¶æ„](docs/design/architecture.md#8-æ•°æ®å¤„ç†æ¶æ„)
    - [9. IO æ¨¡å—æ¶æ„](docs/design/architecture.md#9-io-æ¨¡å—æ¶æ„)
    - [10. PNNX æ¨ç†æ¶æ„](docs/design/architecture.md#10-pnnx-æ¨ç†æ¶æ„)
    - [11. åº”ç”¨ç¤ºä¾‹](docs/design/architecture.md#11-åº”ç”¨ç¤ºä¾‹)
  - [ç®—å­è®¾è®¡ç†è®º](docs/design/operators_theory.md) - ç®—å­æ•°å­¦åŸç†è¯¦è§£
    - **æ•°å­¦è¿ç®—ç®—å­**ï¼šAdd, Sub, Mul, Div, MatMul, Pow, Exp, Log, Neg, Square, Sum, BroadcastTo, SumTo
    - **æ¿€æ´»å‡½æ•°ç®—å­**ï¼šReLU, Sigmoid, Softmax, SiLU
    - **å·ç§¯è¿ç®—ç®—å­**ï¼šConv2d
    - **æ± åŒ–è¿ç®—ç®—å­**ï¼šMaxPool2d, AvgPool2d, AdaptiveAvgPool2d
    - **å½¢çŠ¶å˜æ¢ç®—å­**ï¼šCat, Split, Reshape, Transpose, Flatten
    - **ç¥ç»ç½‘ç»œå±‚ç®—å­**ï¼šDropout, Upsample, Identity
    - **å½’ä¸€åŒ–ç®—å­**ï¼šBatchNorm
    - **æŸå¤±å‡½æ•°ç®—å­**ï¼šSoftmaxCrossEntropy
- **[ç”¨æˆ·æŒ‡å—](docs/user_guide/)** - API æ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—
  - [API æ–‡æ¡£](docs/user_guide/api.md) - å®Œæ•´çš„ API å‚è€ƒ
  - [ä¸ PyTorch å¯¹æ¯”](docs/user_guide/compare.md) - API å¯¹æ¯”å’Œè¿ç§»æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ“¦ ä¸‹è½½æ•°æ®å’Œæ¨¡å‹ï¼ˆå¯é€‰ï¼‰

è¿è¡ŒæŸäº›ç¤ºä¾‹ç¨‹åºï¼ˆå¦‚ MNISTã€YOLOv5ã€ResNetï¼‰éœ€è¦ä¸‹è½½æ•°æ®é›†å’Œæ¨¡å‹æ–‡ä»¶ï¼š

```bash
# ä½¿ç”¨è‡ªåŠ¨ä¸‹è½½è„šæœ¬ï¼ˆæ¨èï¼‰
bash scripts/download_data.sh

# æˆ–æ‰‹åŠ¨ä¸‹è½½ï¼šè®¿é—® GitHub Releases é¡µé¢ä¸‹è½½å‹ç¼©åŒ…å¹¶è§£å‹
```

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒï¼š

- [æ•°æ®ä¸‹è½½è¯´æ˜](data/README.md)
- [æ¨¡å‹ä¸‹è½½è¯´æ˜](model/README.md)

### ç¼–è¯‘é¡¹ç›®

#### åŸºæœ¬ç¼–è¯‘å‘½ä»¤

**ä½¿ç”¨ OriginMat åç«¯ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰**

```bash
# åŸºæœ¬ç¼–è¯‘ï¼ˆè‡ªåŠ¨æ£€æµ‹ CUDAï¼Œå¦‚æœç³»ç»Ÿæœ‰ CUDA ä¼šè‡ªåŠ¨å¯ç”¨ï¼‰
bash ./build.sh

# æˆ–æ˜¾å¼æŒ‡å®šåç«¯å’Œ CUDA æ”¯æŒ
bash ./build.sh origin --cuda

# ä»…ä½¿ç”¨ CPUï¼ˆç¦ç”¨ CUDAï¼‰
bash ./build.sh origin
```

**ä½¿ç”¨ LibTorch åç«¯ï¼ˆå¯é€‰ï¼‰**

> **æ³¨æ„**ï¼šæœ¬é¡¹ç›®æ”¯æŒ LibTorch ä½œä¸ºçŸ©é˜µè®¡ç®—åç«¯ï¼Œä¸»è¦ç”¨äºå±•ç¤º OriginDL çš„å¤šåç«¯æ¶æ„è®¾è®¡èƒ½åŠ›ã€‚ä½† LibTorch åç«¯çš„é€‚é…å·¥ä½œå°šæœªå®Œå…¨å®Œæˆï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨ OriginMat åç«¯ã€‚

å¦‚æœå¸Œæœ›ä½¿ç”¨ LibTorch åšçŸ©é˜µè®¡ç®—åç«¯ï¼ˆæœ¬é¡¹ç›®æœ¬èº«ä¸ä¾èµ– libtorchï¼‰ï¼Œéœ€è¦å…ˆä¸‹è½½ LibTorchï¼š

```bash
# ä¸‹è½½ LibTorch
cd 3rd
wget https://download.pytorch.org/libtorch/cpu/libtorch-cxx11-abi-shared-with-deps-2.1.0%2Bcpu.zip
unzip libtorch-cxx11-abi-shared-with-deps-2.1.0+cpu.zip
cd ..

# ä½¿ç”¨ LibTorch åç«¯ç¼–è¯‘
bash ./build.sh torch
```

#### å…¶ä»–ç¼–è¯‘é€‰é¡¹

`build.sh` è„šæœ¬è¿˜æ”¯æŒä»¥ä¸‹å¯é€‰å‚æ•°ï¼š

- `--nvcc /path/to/nvcc`ï¼šæŒ‡å®š CUDA ç¼–è¯‘å™¨è·¯å¾„
- `--libtorch_path /path/to/libtorch`ï¼šæŒ‡å®š LibTorch è·¯å¾„
- `--build_dir /path/to/build`ï¼šæŒ‡å®šæ„å»ºç›®å½•ï¼ˆé»˜è®¤ï¼š`build` æˆ– `torch_build`ï¼‰

å¯¹äºæŸäº› example(å¦‚example_yolov5, example_resnet)ï¼Œéœ€è¦ opencv çš„æ”¯æŒï¼Œæ²¡æœ‰ opencv å°†ä¸ä¼šç¼–è¯‘

```shell
sudo apt install libopencv-dev -y
```

ç¼–è¯‘å®Œæˆåï¼Œä¼šåœ¨ä»¥ä¸‹ä½ç½®ç”Ÿæˆæ–‡ä»¶ï¼š

- `build/libs/origindl.so` - ä¸»åº“æ–‡ä»¶
- `build/bin/` - æµ‹è¯•ç¨‹åºå’Œç¤ºä¾‹ç¨‹åº

### ç³»ç»Ÿè¦æ±‚

ä»¥ä¸‹ä¸ºæœ¬äººçš„ç¼–è¯‘ç¯å¢ƒï¼Œæ›´ä½ç‰ˆæœ¬çš„ CMake ä¸ C++ æ ‡å‡†äº¦å¯æ”¯æŒã€‚

- **ç¼–è¯‘å™¨**ï¼šæ”¯æŒ C++20ï¼ˆGCC 9+ã€Clang 10+ï¼‰
- **CMake**ï¼š3.25
- **CUDA**ï¼ˆå¯é€‰ï¼‰ï¼šä½¿ç”¨ `--cuda` ç¼–è¯‘æ—¶éœ€å®‰è£… CUDA å·¥å…·é“¾
- **OpenCV**ï¼ˆå¯é€‰ï¼‰ï¼šYOLOv5ã€ResNet ç­‰å›¾åƒç¤ºä¾‹éœ€ `libopencv-dev`

## ğŸ“– åŸºæœ¬ä½¿ç”¨

### åˆ›å»ºå¼ é‡

| åŠŸèƒ½           | PyTorch ç¤ºä¾‹ä»£ç                          | OriginDL ç¤ºä¾‹ä»£ç                            | å¤‡æ³¨                             |
| -------------- | ---------------------------------------- | ------------------------------------------- | -------------------------------- |
| ä»æ•°æ®åˆ›å»ºå¼ é‡ | `torch.tensor([[1.0, 2.0], [3.0, 4.0]])` | `Tensor({1.0, 2.0, 3.0, 4.0}, Shape{2, 2})` | OriginDL ä½¿ç”¨ Shape å¯¹è±¡æŒ‡å®šå½¢çŠ¶ |
| åˆ›å»ºå…¨é›¶å¼ é‡   | `torch.zeros(3, 3)`                      | `Tensor::zeros(Shape{3, 3})`                | è¯­æ³•é«˜åº¦ç›¸ä¼¼                     |
| åˆ›å»ºå…¨ä¸€å¼ é‡   | `torch.ones(2, 2)`                       | `Tensor::ones(Shape{2, 2})`                 | è¯­æ³•é«˜åº¦ç›¸ä¼¼                     |
| åˆ›å»ºéšæœºå¼ é‡   | `torch.randn(2, 2)`                      | `Tensor::randn(Shape{2, 2})`                | è¯­æ³•é«˜åº¦ç›¸ä¼¼                     |
| åˆ›å»ºæ ‡é‡å¼ é‡   | `torch.tensor(5.0)`                      | `Tensor(5.0, Shape{1})`                     | OriginDL éœ€è¦æ˜¾å¼æŒ‡å®šå½¢çŠ¶        |

### è¿ç®—

| ç±»åˆ«     | PyTorch ç¤ºä¾‹ä»£ç                          | OriginDL ç¤ºä¾‹ä»£ç                             | å¤‡æ³¨                     |
| -------- | ------------------------------- | ----------------------------------- | ------------------------ |
| æ•°å­¦è¿ç®— | `a + b`ã€`torch.exp(a)`ã€`a @ b` | `a + b`ã€`exp(a)`ã€`matmul(a, b)`   | è¿ç®—ç¬¦ä¸€è‡´ï¼Œå‡½æ•°ç”¨å…¨å±€å½¢å¼ |
| å½¢çŠ¶è¿ç®— | `x.reshape(s)`ã€`x.T`ã€`flatten(x)` | `reshape(x, s)`ã€`transpose(x)`ã€`flatten(x)` | å‡½æ•°å¼è°ƒç”¨               |
| æ¿€æ´»è¿ç®— | `F.relu(x)`ã€`F.sigmoid(x)`      | `relu(x)`ã€`sigmoid(x)`             | å…¨å±€å‡½æ•°å½¢å¼             |
| å·ç§¯è¿ç®— | `F.conv2d(x, w, stride, pad)`    | `conv2d(x, w, stride, pad)`         | å‚æ•°é¡ºåºä¸€è‡´             |

### è‡ªåŠ¨æ±‚å¯¼

| åŠŸèƒ½     | PyTorch ç¤ºä¾‹ä»£ç            | OriginDL ç¤ºä¾‹ä»£ç           | å¤‡æ³¨                  |
| -------- | -------------------------- | -------------------------- | --------------------- |
| å‰å‘ä¼ æ’­ | `z = x * y + torch.exp(x)` | `auto z = x * y + exp(x);` | è¯­æ³•é«˜åº¦ç›¸ä¼¼          |
| åå‘ä¼ æ’­ | `z.backward()`             | `z.backward()`             | è¯­æ³•å®Œå…¨ä¸€è‡´          |
| è·å–æ¢¯åº¦ | `x.grad`                   | `x.grad()`                 | OriginDL ä½¿ç”¨å‡½æ•°è°ƒç”¨ |
| æ‰“å°æ¢¯åº¦ | `print(x.grad)`            | `x.grad().print("dx: ")`   | OriginDL ä½¿ç”¨æˆå‘˜å‡½æ•° |

### nn æ¨¡å—

| ç±»åˆ«   | PyTorch ç¤ºä¾‹ä»£ç                           | OriginDL ç¤ºä¾‹ä»£ç                              | å¤‡æ³¨           |
| ------ | -------------------------------- | ------------------------------------ | -------------- |
| æ¨¡å‹   | `nn.Sequential(Linear(...), ...)` | `nn::MLP({784, 100, 10})`            | é¢„ç½® MLP ç­‰    |
| å‰å‘   | `model(x)`                       | `model.forward(x)`                   | éœ€æ˜¾å¼ forward |
| æ¨¡å¼   | `model.train()` / `model.eval()` | `model.train(true)` / `model.train(false)` | æ¥å£ç›¸è¿‘       |

### ä¼˜åŒ–å™¨ä¸æŸå¤±

| ç±»åˆ«   | PyTorch ç¤ºä¾‹ä»£ç                      | OriginDL ç¤ºä¾‹ä»£ç                          | å¤‡æ³¨           |
| ------ | --------------------------- | -------------------------------- | -------------- |
| ä¼˜åŒ–å™¨ | `optim.Adam(model.parameters(), lr)` | `Adam optimizer(model, lr)`       | ä¼ å…¥ Module    |
| æ­¥è¿›   | `optimizer.step()`ã€`optimizer.zero_grad()` | åŒå·¦                              | ç”¨æ³•ä¸€è‡´       |
| æŸå¤±   | `F.cross_entropy(logits, target)`   | `softmax_cross_entropy(x, target)` | å‡½æ•°å¼è°ƒç”¨     |

### æ•°æ®åŠ è½½

| ç±»åˆ« | PyTorch ç¤ºä¾‹ä»£ç                         | OriginDL ç¤ºä¾‹ä»£ç                          | å¤‡æ³¨           |
| ---- | ------------------------------ | -------------------------------- | -------------- |
| åŠ è½½ | `DataLoader(dataset, batch_size)` | `DataLoader(dataset, batch_size)` | ç”¨æ³•ä¸€è‡´       |

## ğŸ“ ç¤ºä¾‹ä»£ç 

### çº¿æ€§å›å½’ï¼ˆæ‰‹å†™ç½‘ç»œï¼‰

å‚è€ƒï¼š`tests/example/linear_regression/linear_regression.cpp`

```cpp
#include "origin.h"
using namespace origin;
namespace F = origin::functional;

// æ‰‹å†™å‰å‘ä¸æŸå¤±
Tensor Predict(const Tensor &x, const Tensor &w, const Tensor &b)
{
    return F::mat_mul(x, w) + b;
}
Tensor MSE(const Tensor &x0, const Tensor &x1)
{
    auto diff = x0 - x1;
    auto sum_result = F::sum(F::pow(diff, Scalar(2.0f)));
    return sum_result / static_cast<float>(diff.elements());
}

float lr = 0.1f;
int iters = 200;
auto w = Tensor(0.0f, Shape{1, 1});
auto b = Tensor(0.0f, Shape{1, 1});
for (int i = 0; i < iters; ++i) {
    w.clear_grad(); b.clear_grad();
    auto y_pred = Predict(x, w, b);
    auto loss = MSE(y, y_pred);
    loss.backward();
    w = w - lr * w.grad();
    b = b - lr * b.grad();
}
```

### çº¿æ€§å›å½’ï¼ˆNN æ¨¡å—ï¼‰

å‚è€ƒï¼š`tests/example/linear_regression/nn_linear.cpp`

```cpp
#include "origin.h"
using namespace origin;
namespace nn = origin::nn;

// Sequential + Linearï¼ŒSGD è®­ç»ƒ
float learning_rate = 0.1f;
int iters = 200;
Sequential model;
model.add(std::make_unique<nn::Linear>(1, 1, true));
SGD optimizer(model, learning_rate);
model.to(device);

model.train();
for (int i = 0; i < iters; ++i) {
    optimizer.zero_grad();
    auto y_pred = model(x);
    auto loss = F::sum(F::pow(y_pred - y, Scalar(2))) / y_pred.elements();
    loss.backward();
    optimizer.step();
}
```

### CNN è®­ç»ƒï¼ˆMNIST + DataLoaderï¼‰

å‚è€ƒï¼š`tests/example/mnist/conv_mnist.cpp`

```cpp
#include "origin.h"
using namespace origin;
namespace F = origin::functional;

MNIST train_dataset("./data/mnist", true);
DataLoader train_loader(train_dataset, 256, true);

SimpleCNN model;  // è‡ªå®šä¹‰ Moduleï¼šConv2d -> BN -> ReLU -> MaxPool -> Flatten -> Linear
model.to(device);
Adam optimizer(model, 0.0001f);
optimizer.register_hook(WeightDecay(1e-4f).hook());

for (int epoch = 0; epoch < 10; ++epoch) {
    model.train(true);
    train_loader.reset();
    while (train_loader.has_next()) {
        auto [x, t] = train_loader.next();
        x = x.to(device); t = t.to(device);
        auto y = model(x);
        auto loss = F::softmax_cross_entropy(y, t);
        optimizer.zero_grad();
        loss.backward();
        optimizer.step();
    }
}
```

### PNNX æ¨¡å‹æ¨ç†ï¼ˆYOLOv5ï¼‰

å‚è€ƒï¼š`tests/example/yolo/yolov5_infer.cpp`

```cpp
#include "origin.h"
using namespace origin::pnnx;

std::string param_path = "model.pnnx.param";
std::string bin_path = "model.pnnx.bin";
int input_h = 640, input_w = 640;

Device device(DeviceType::kCPU);
if (cuda::is_available()) device = Device(DeviceType::kCUDA, 0);

PNNXGraph graph(param_path, bin_path);
graph.build();

Tensor input = create_test_input(device, 1, 3, input_h, input_w);

// å›¾åƒè¾“å…¥ï¼ˆéœ€ OpenCVï¼Œletterbox + BGR2RGB + å½’ä¸€åŒ– -> NCHWï¼‰
Tensor input = preprocess_image(cv_image, device, input_h, input_w);

graph.set_inputs("pnnx_input_0", {input});
graph.forward(false);
auto outputs = graph.get_outputs("pnnx_output_0");
// åå¤„ç†ï¼šè§£ææ£€æµ‹æ¡†ã€NMSã€ç»˜åˆ¶ç­‰ï¼Œè§æºç  process_and_save_detection
```

## ğŸ§ª è¿è¡Œæµ‹è¯•

### å•å…ƒæµ‹è¯•

é¡¹ç›®åŒ…å«å®Œæ•´çš„å•å…ƒæµ‹è¯•ï¼Œå¯ä»¥éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§ï¼š

```bash
# è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•
bash run_unit_test.sh

# è¿è¡Œ CUDA å•å…ƒæµ‹è¯•ï¼ˆå¦‚æœæ”¯æŒï¼‰
bash run_unit_test.sh --cuda
```

### æ€§èƒ½æµ‹è¯•

è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼Œå¯¹æ¯” OriginDL ä¸ PyTorch çš„æ€§èƒ½ï¼š

```bash
# è¿è¡Œæ‰€æœ‰ benchmark æµ‹è¯•ï¼Œæ‰€æœ‰è®¾å¤‡ï¼ˆCPU/CUDAï¼‰ã€æ‰€æœ‰ç®—å­çš„æµ‹è¯•ï¼Œä¸å»ºè®®å¼€å¯ cpu çš„æµ‹è¯•ï¼Œå› ä¸º CPU ä»…ä»…ç”¨äºéªŒè¯çš„ç›®çš„ï¼Œæ€§èƒ½å…¶å®å¾ˆæ…¢
python3 run_benchmark.py
python3 run_benchmark.py -d cuda  # æœ€å¸¸ç”¨çš„æµ‹è¯•æ–¹å¼ï¼Œåªæµ‹é‡ CUDA è®¾å¤‡çš„æ‰€æœ‰ç®—å­çš„æ€§èƒ½

# è¿è¡Œç‰¹å®šç®—å­çš„ benchmark
python3 run_benchmark.py -f add
python3 run_benchmark.py -f conv2d

# è¿è¡Œå¤šä¸ªç®—å­çš„ benchmarkï¼ˆé€—å·åˆ†éš”ï¼‰
python3 run_benchmark.py -f add,sub,mul,div
python3 run_benchmark.py -f relu,sigmoid,softmax

# æŒ‡å®šè®¾å¤‡è¿è¡Œï¼ˆCPU æˆ– CUDAï¼‰
python3 run_benchmark.py -f add -d cpu
python3 run_benchmark.py -f add -d cuda:0

# æŒ‡å®šç‰¹å®šçš„ shape è¿›è¡Œæµ‹è¯•
python3 run_benchmark.py -f add -d cuda:0 -s 1000,1000

# è‡ªå®šä¹‰é¢„çƒ­å’Œé‡å¤æ¬¡æ•°
python3 run_benchmark.py -f add -w 5 -r 50

# æµ‹è¯•å°±åœ°æ“ä½œï¼ˆinplace operationsï¼‰
python3 run_benchmark.py -f add --inplace

# å¯¼å‡ºæ€§èƒ½æ•°æ®åˆ° Excel æ–‡ä»¶
python3 run_benchmark.py -f add -d cuda:0 -o ./benchmark_results
python3 run_benchmark.py -f add,sub,mul,div -d cuda:0 -o ./benchmark_results
python3 run_benchmark.py -d cuda:0 -o ./benchmark_results  # æµ‹è¯•æ‰€æœ‰ç®—å­å¹¶å¯¼å‡º

# ç»„åˆä½¿ç”¨å¤šä¸ªå‚æ•°
python3 run_benchmark.py -f conv2d,relu -d cuda:0 -w 2 -r 10 -o ./results
```

**Excel è¾“å‡ºè¯´æ˜ï¼š**

- `-o` å‚æ•°æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œæ–‡ä»¶ä¼šè‡ªåŠ¨ç”Ÿæˆ
- å•ç®—å­æµ‹è¯•ï¼šç”Ÿæˆ `benchmark_{operator}_{timestamp}.xlsx`
- å¤šç®—å­æµ‹è¯•ï¼šç”Ÿæˆ `benchmark_{operator1}_{operator2}_{timestamp}.xlsx`ï¼ŒåŒ…å«æ¯ä¸ªç®—å­çš„ç‹¬ç«‹ Sheet å’Œç»Ÿä¸€çš„æ±‡æ€» Sheet
- å…¨éƒ¨æµ‹è¯•ï¼šç”Ÿæˆ `benchmark_all_{timestamp}.xlsx`
- Excel æ–‡ä»¶åŒ…å«é¢œè‰²æ ‡è®°ï¼šçº¢è‰²ï¼ˆSpeedup â‰¤ 0.6ï¼‰ã€é»„è‰²ï¼ˆ0.6 < Speedup â‰¤ 0.8ï¼‰ã€ç»¿è‰²ï¼ˆ0.8 < Speedup â‰¤ 0.9ï¼‰

### ç¤ºä¾‹ç¨‹åº

ç¼–è¯‘æˆåŠŸåï¼Œå¯ä»¥åœ¨ `build/bin/` ç›®å½•ä¸‹æ‰¾åˆ°å„ç§ç¤ºä¾‹ç¨‹åºï¼š

æ›´å¤šç¤ºä¾‹è¯·å‚è€ƒ `tests/example/` ç›®å½•ï¼š

- `linear_regression/` - çº¿æ€§å›å½’è®­ç»ƒ
- `mnist/` - MNIST æ•°æ®é›†è®­ç»ƒï¼ˆMLP å’Œ CNNï¼‰
- `resnet/` - ResNet åˆ†ç±»æ¨ç†
- `yolo/` - YOLOv5 ç›®æ ‡æ£€æµ‹æ¨ç†

## â“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æ·»åŠ æ–°çš„ç®—å­ï¼Ÿ

A: å‚è€ƒç°æœ‰ç®—å­çš„å®ç°ï¼Œç»§æ‰¿ `Operator` ç±»å¹¶å®ç° `forward` å’Œ `backward` æ–¹æ³•ã€‚è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [ç®—å­è®¾è®¡ç†è®º](docs/design/operators_theory.md)ã€‚

### Q: å¦‚ä½•ä» PyTorch è¿ç§»ä»£ç ï¼Ÿ

A: OriginDL æä¾›äº†ä¸ PyTorch é«˜åº¦ç›¸ä¼¼çš„ APIï¼Œå¤§éƒ¨åˆ†ä»£ç å¯ä»¥ç›´æ¥è¿ç§»ã€‚è¯¦ç»†å¯¹æ¯”è¯·å‚è€ƒ [ä¸ PyTorch å¯¹æ¯”](docs/user_guide/compare.md) æ–‡æ¡£ã€‚

### Q: å¦‚ä½•é€‰æ‹©è®¡ç®—åç«¯ï¼Ÿ

A: é»˜è®¤ä½¿ç”¨ OriginMat åç«¯ï¼ˆè‡ªç ”å®ç°ï¼‰ï¼Œå¦‚éœ€ä½¿ç”¨ LibTorch åç«¯ï¼Œç¼–è¯‘æ—¶ä½¿ç”¨ `bash build.sh torch`ã€‚ä¸¤ç§åç«¯ API å®Œå…¨å…¼å®¹ã€‚

### Q: æ˜¯å¦æ”¯æŒ GPU åŠ é€Ÿï¼Ÿ

A: æ˜¯çš„ï¼ŒOriginMat åç«¯æ”¯æŒ CUDA åŠ é€Ÿã€‚ç¼–è¯‘æ—¶å¯ç”¨ CUDA æ”¯æŒï¼š`bash build.sh --cuda`ã€‚

### Q: å¦‚ä½•è´¡çŒ®ä»£ç ï¼Ÿ

A: æ¬¢è¿æäº¤ Issue å’Œ Pull Requestã€‚è¯·å‚è€ƒ [ä»£ç è§„èŒƒ](CODE_STYLE.md) ç¡®ä¿ä»£ç é£æ ¼ä¸€è‡´ã€‚

## ğŸ“ˆ é¡¹ç›®çŠ¶æ€

æŸ¥çœ‹ [MILESTONES.md](MILESTONES.md) äº†è§£é¡¹ç›®å¼€å‘é‡Œç¨‹ç¢‘å’Œè®¡åˆ’ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ BSD 3-Clause è®¸å¯è¯ï¼Œè¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚
